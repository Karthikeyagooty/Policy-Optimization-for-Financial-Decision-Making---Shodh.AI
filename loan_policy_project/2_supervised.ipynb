{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b31e81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_recall_fscore_support\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from data_utils import load_data, select_and_clean, encode_and_split\n",
    "\n",
    "DATA_PATH = './data/accepted_2007_to_2018.csv'\n",
    "df = load_data(DATA_PATH, nrows=200000)\n",
    "proc = select_and_clean(df)\n",
    "X_train, X_test, y_train, y_test, scaler = encode_and_split(proc, test_size=0.2)\n",
    "\n",
    "# Convert to torch tensors\n",
    "X_train_t = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "y_train_t = torch.tensor(y_train.values, dtype=torch.float32).unsqueeze(1)\n",
    "X_test_t = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "y_test_t = torch.tensor(y_test.values, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "train_ds = TensorDataset(X_train_t, y_train_t)\n",
    "train_loader = DataLoader(train_ds, batch_size=256, shuffle=True)\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "model = MLP(X_train.shape[1])\n",
    "opt = optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "# Training loop (minimal)\n",
    "for epoch in range(5):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for xb, yb in train_loader:\n",
    "        opt.zero_grad()\n",
    "        preds = model(xb)\n",
    "        loss = loss_fn(preds, yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        total_loss += loss.item() * xb.size(0)\n",
    "    print(f'Epoch {epoch+1} loss = {total_loss/len(train_ds):.4f}')\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    probs = model(X_test_t).numpy().ravel()\n",
    "    preds = (probs >= 0.5).astype(int)\n",
    "    auc = roc_auc_score(y_test.values, probs)\n",
    "    f1 = f1_score(y_test.values, preds)\n",
    "    print('AUC:', auc)\n",
    "    print('F1:', f1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a89a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the grid-search best model and evaluate with threshold sweep\n",
    "import json\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "\n",
    "PROJECT_ROOT = Path('.') / ''\n",
    "MODEL_DIR = Path('models')\n",
    "DATA_DIR = Path('data')\n",
    "metrics_path = MODEL_DIR / 'grid_best_metrics.json'\n",
    "state_path = MODEL_DIR / 'mlp_grid_best.pth'\n",
    "assert metrics_path.exists(), 'grid_best_metrics.json not found. Run grid search first.'\n",
    "best = json.loads(metrics_path.read_text())\n",
    "cfg = best['best_config'] if 'best_config' in best else best.get('config', {})\n",
    "hidden = tuple(cfg.get('hidden_dims', [256,128]))\n",
    "dropout = cfg.get('dropout', 0.2)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# load test set\n",
    "if (DATA_DIR / 'test.parquet').exists():\n",
    "    df_test = pd.read_parquet(DATA_DIR / 'test.parquet')\n",
    "else:\n",
    "    df_test = pd.read_parquet(DATA_DIR / 'processed_sample.parquet')\n",
    "feat_cols = [c for c in df_test.columns if c != 'target']\n",
    "X_test = df_test[feat_cols].to_numpy(dtype=np.float32)\n",
    "y_test = df_test['target'].to_numpy(dtype=np.int32)\n",
    "\n",
    "class MLPGrid(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims=(256,128), dropout=0.2):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        prev = input_dim\n",
    "        for h in hidden_dims:\n",
    "            layers.append(nn.Linear(prev, h))\n",
    "            layers.append(nn.BatchNorm1d(h))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "            prev = h\n",
    "        layers.append(nn.Linear(prev, 1))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "    def forward(self, x):\n",
    "        return self.net(x).squeeze(-1)\n",
    "\n",
    "model = MLPGrid(input_dim=len(feat_cols), hidden_dims=hidden, dropout=dropout).to(device)\n",
    "if state_path.exists():\n",
    "    model.load_state_dict(torch.load(state_path, map_location=device))\n",
    "else:\n",
    "    raise FileNotFoundError('Saved model not found at ' + str(state_path))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    Xb = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "    logits = model(Xb).cpu().numpy()\n",
    "    probs = 1.0 / (1.0 + np.exp(-logits))\n",
    "\n",
    "# compute AUC and sweep threshold for best F1 on test\n",
    "auc = roc_auc_score(y_test, probs)\n",
    "thresholds = np.linspace(0.01, 0.99, 99)\n",
    "best_f1 = -1.0\n",
    "best_thr = 0.5\n",
    "for thr in thresholds:\n",
    "    preds = (probs >= thr).astype(int)\n",
    "    f1 = f1_score(y_test, preds)\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1; best_thr = float(thr)\n",
    "\n",
    "print('Loaded best config:', cfg)\n",
    "print(f'Test AUC: {auc:.4f}, Best test F1: {best_f1:.4f} at threshold={best_thr:.3f}')\n",
    "\n",
    "# save final metrics\n",
    "out = {'test_auc': float(auc), 'test_f1': float(best_f1), 'best_threshold': best_thr, 'config': cfg}\n",
    "(MODEL_DIR / 'final_best_metrics.json').write_text(json.dumps(out, indent=2))\n",
    "print('Saved final metrics to', MODEL_DIR / 'final_best_metrics.json')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
